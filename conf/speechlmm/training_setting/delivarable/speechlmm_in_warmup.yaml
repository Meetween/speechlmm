# @package _global_

defaults:
  - _self_

wandb_project: speechlmm
deepspeed_config: ${oc.env:SPEECHLMM_ROOT}/conf/deepspeed/zero2.json

data:
  data_config_path: ${oc.env:SPEECHLMM_ROOT}/conf/datasets/delivarable/speech_in_warmup.yml
  rebuild_dataset_cache: false
  num_proc_for_preprocessing: 64

  task_weights:
    ASR: 0.5
    ST: 0.5

  multi_task_sampler: "alternating"

  group_dataset_by_task:
    train: true

training:
  per_device_train_batch_size: 4
  gradient_accumulation_steps: 2
  save_steps: 1000
  save_total_limit: 10
  num_train_epochs: 1
  eval_strategy: "no"
  attn_implementation: flash_attention_2
  dataloader_num_workers: 4

  learning_rate: 8.0e-5

  freeze_modules:
    - audio_encoder
    - text_decoder

  group_by_modality_length: false
  report_to: wandb

model:
  add_all_multimodal_tokens: true
  audio_adapter:
    hidden_layers: 4


# python speechlmm/train/train_hydra.py \
#     --config-name pretrain \
#     model/audio_encoder=seamless \
#     model/audio_adapter=mlp \
#     model/text_decoder=llama_3_1 \
#     training_setting=delivarable/speechlmm_in_warmup
