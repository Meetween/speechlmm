# @package _global_

defaults:
  - speechlmm/v1_warmup/base
  - override /model/text_decoder: llama_3_3b
  - _self_

run_name: speechlmm-m

training:
  per_device_train_batch_size: 24
  learning_rate: 7.5e-5
  save_steps: 2000
