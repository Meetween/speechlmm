# conversation template
# OUTPUTS_TEXT_LIST: "speechlmm/dataset/OUTPUTS_TEXT_LIST.json"
INPUTS_TEXT_LIST: "speechlmm/dataset/INPUTS_TEXT_LIST.json"

# data
DATA:
# WARNING!!! Don't forget the '-' before each dataset, must be parsed as a list
    - LibriTTS: # same name of the dataset class
        datapath: ${DATA_HOME}/parler_tts/LibriTTS-R-Filtered
        task: "TTS" # one task per dataset, you can duplicate the dataset and change the task
        languages: ["en"]
        partitions:
            train-clean-100: # the name of the partition of your dataset, could be any name, such as "train-other-500" or "my-custom-partition"
                amount: ":100%"  # options: ":X%" or "X1:X2%"
                min_duration: 0.1
                max_duration: null
                destination: "train"
            train-clean-360:
                amount: ":100%"
                min_duration: 0.1
                max_duration: null
                destination: "train"
            train-other-500:
                amount: ":100%"
                min_duration: 0.1
                max_duration: null
                destination: "train"
        additional_args:
            add_speaker_descriptions: false
    - NllbParacrawl: # same name of the dataset class
        datapath: ${DATA_HOME}/NLLBParaCrawl2M
        task: "MT"
        languages: ["de-en", "en-es", "en-fr", "en-it"]
        partitions:
            train:
                amount: ":1%"
                destination: "train"
    - Alpaca:
        datapath: ${DATA_HOME}/alpaca
        task: "TextInstruct"
        languages: ["en"]
        partitions:
            train:
                amount: ":100%"
                destination: "train"
